#include "deepgalois/layers/relu_layer.h"

namespace deepgalois {

#ifdef CPU_ONLY
// ğ‘¦[ğ‘™] = max(0, ğ‘¦[ğ‘™âˆ’1])
void relu_layer::forward_propagation(const float_t* in_data, float_t* out_data) {
  size_t n = input_dims[0] * input_dims[1];
  galois::do_all(galois::iterate((size_t)0, n), [&](const auto& i) {
    out_data[i] = std::max(in_data[i], (float_t)0);
  }, galois::chunk_size<64>(), galois::steal(), galois::loopname("relu_layer-fw"));
}

// ğœ•ğ¿ / ğœ•ğ‘¦[ğ‘™âˆ’1] = 0, ğ‘–ğ‘“ (ğ‘¦[ğ‘™] < 0)
//              = ğœ•ğ¿ / ğœ•ğ‘¦ğ‘™, ğ‘œğ‘¡â„ğ‘’ğ‘Ÿğ‘¤ğ‘–ğ‘ ğ‘’
void relu_layer::back_propagation(const float_t* in_data, const float_t* out_data,
                                  float_t* out_grad, float_t* in_grad) {
  size_t n = input_dims[0] * input_dims[1];
  galois::do_all(galois::iterate((size_t)0, n), [&](const auto& i) {
    in_grad[i] = out_data[i] > float_t(0) ? out_grad[i] : float_t(0);
  }, galois::chunk_size<64>(), galois::steal(), galois::loopname("relu_layer-bw"));
}
#endif

} // namespace
